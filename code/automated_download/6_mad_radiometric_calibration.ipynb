{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71b729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from osgeo import gdal, gdalconst\n",
    "from numpy.linalg import inv, eig\n",
    "from scipy.stats import chi2\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c1bad",
   "metadata": {
    "code_folding": [
     7,
     18,
     81
    ]
   },
   "outputs": [],
   "source": [
    "# IRMAD functions from https://github.com/ChenHongruixuan/ChangeDetectionRepository\n",
    "\n",
    "'''\n",
    "Python implementation of IRMAD\n",
    "A. A. Nielsen, “The regularized iteratively reweighted MAD method for change detection in multi- and hyperspectral data,” IEEE Trans. Image Process., vol. 16, no. 2, pp. 463–478, 2007.\n",
    "'''\n",
    "\n",
    "def covw(center_X, center_Y, w):\n",
    "    n = w.shape[1]\n",
    "    sqrt_w = np.sqrt(w)\n",
    "    sum_w = w.sum()\n",
    "    V = np.concatenate((center_X, center_Y), axis=0)\n",
    "    V = sqrt_w * V\n",
    "    dis = np.dot(V, V.T) / sum_w * (n / (n - 1))\n",
    "\n",
    "    return dis\n",
    "\n",
    "# max_iter = 1 is the same as MAD\n",
    "def IRMAD(img_X, img_Y, max_iter=50, epsilon=1e-3):\n",
    "    bands_count_X, num = img_X.shape\n",
    "\n",
    "    weight = np.ones((1, num))  # (1, height * width)\n",
    "    can_corr = 100 * np.ones((bands_count_X, 1))\n",
    "    for _iter in range(max_iter):\n",
    "        print(_iter)\n",
    "        mean_X = np.sum(weight * img_X, axis=1, keepdims=True) / np.sum(weight)\n",
    "        mean_Y = np.sum(weight * img_Y, axis=1, keepdims=True) / np.sum(weight)\n",
    "\n",
    "        # centralization\n",
    "        center_X = img_X - mean_X\n",
    "        center_Y = img_Y - mean_Y\n",
    "        \n",
    "        # also can use np.cov, but the result would be sightly different with author' result acquired by MATLAB code\n",
    "        cov_XY = covw(center_X, center_Y, weight)\n",
    "        size = cov_XY.shape[0]\n",
    "        sigma_11 = cov_XY[0:bands_count_X, 0:bands_count_X]  # + 1e-4 * np.identity(3)\n",
    "        sigma_22 = cov_XY[bands_count_X:size, bands_count_X:size]  # + 1e-4 * np.identity(3)\n",
    "        sigma_12 = cov_XY[0:bands_count_X, bands_count_X:size]  # + 1e-4 * np.identity(3)\n",
    "        sigma_21 = sigma_12.T\n",
    "\n",
    "        tgt_mat = np.dot(np.dot(np.dot(inv(sigma_11), sigma_12), inv(sigma_22)), sigma_21)\n",
    "        eigenvalue, eigenvector_X = eig(tgt_mat)  # the eigenvalue and eigenvector of image X\n",
    "        # sort eigenvector based on the size of eigenvalue\n",
    "        eigenvalue = np.sqrt(eigenvalue)\n",
    "\n",
    "        idx = eigenvalue.argsort()\n",
    "        eigenvalue = eigenvalue[idx]\n",
    "\n",
    "        if (_iter + 1) == 1:\n",
    "            print('Canonical correlations')\n",
    "        print(eigenvalue)\n",
    "\n",
    "        eigenvector_X = eigenvector_X[:, idx]\n",
    "\n",
    "        eigenvector_Y = np.dot(np.dot(inv(sigma_22), sigma_21), eigenvector_X)  # the eigenvector of image Y\n",
    "\n",
    "        # tune the size of X and Y, so the constraint condition can be satisfied\n",
    "        norm_X = np.sqrt(1 / np.diag(np.dot(eigenvector_X.T, np.dot(sigma_11, eigenvector_X))))\n",
    "        norm_Y = np.sqrt(1 / np.diag(np.dot(eigenvector_Y.T, np.dot(sigma_22, eigenvector_Y))))\n",
    "        eigenvector_X = norm_X * eigenvector_X\n",
    "        eigenvector_Y = norm_Y * eigenvector_Y\n",
    "\n",
    "        mad_variates = np.dot(eigenvector_X.T, center_X) - np.dot(eigenvector_Y.T, center_Y)  # (6, width * height)\n",
    "\n",
    "        if np.max(np.abs(can_corr - eigenvalue)) < epsilon:\n",
    "            break\n",
    "        can_corr = eigenvalue\n",
    "        # calculate chi-square distance and probility of unchanged\n",
    "        mad_var = np.reshape(2 * (1 - can_corr), (bands_count_X, 1))\n",
    "        chi_square_dis = np.sum(mad_variates * mad_variates / mad_var, axis=0, keepdims=True)\n",
    "        weight = 1 - chi2.cdf(chi_square_dis, bands_count_X)\n",
    "\n",
    "    if (_iter + 1) == max_iter:\n",
    "        print('the canonical correlation may not be converged')\n",
    "    else:\n",
    "        print('the canonical correlation is converged, the iteration is %d' % (_iter + 1))\n",
    "\n",
    "    return mad_variates, can_corr, mad_var, eigenvector_X, eigenvector_Y, \\\n",
    "           sigma_11, sigma_22, sigma_12, chi_square_dis, weight\n",
    "\n",
    "\n",
    "def get_binary_change_map(data):\n",
    "    \"\"\"\n",
    "    get binary change map\n",
    "    :param data:\n",
    "    :param method: cluster method\n",
    "    :return: binary change map\n",
    "    \"\"\"\n",
    "\n",
    "    cluster_center = KMeans(n_clusters=2, max_iter=1500).fit(data.T).cluster_centers_.T  # shape: (1, 2)\n",
    "    # cluster_center = k_means_cluster(weight, cluster_num=2)\n",
    "    print('k-means cluster is done, the cluster center is ', cluster_center)\n",
    "    dis_1 = np.linalg.norm(data - cluster_center[0, 0], axis=0, keepdims=True)\n",
    "    dis_2 = np.linalg.norm(data - cluster_center[0, 1], axis=0, keepdims=True)\n",
    "\n",
    "    bcm = np.copy(data)  # binary change map\n",
    "    if cluster_center[0, 0] > cluster_center[0, 1]:\n",
    "        bcm[dis_1 > dis_2] = 1\n",
    "        bcm[dis_1 <= dis_2] = 0\n",
    "    else:\n",
    "        bcm[dis_1 > dis_2] = 0\n",
    "        bcm[dis_1 <= dis_2] = 1\n",
    "\n",
    "    return bcm # 1 = invariant pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb30f8",
   "metadata": {
    "code_folding": [
     1,
     5
    ]
   },
   "outputs": [],
   "source": [
    "# reprojection function\n",
    "def reproj_to_sentinel(tgt, ref):\n",
    "    return(tgt.rio.reproject_match(ref))\n",
    "    \n",
    "# linear model function\n",
    "def lm_coefs(df):\n",
    "    x = np.array(df[ ~np.isnan(df['tgt'])]['tgt']).reshape(-1, 1)\n",
    "    y = np.array(df[ ~np.isnan(df['ref'])]['ref']).reshape(-1, 1)\n",
    "    return pd.DataFrame({'tgt_file': pd.Series(df['tgt_file'][0]),\n",
    "                         'tgt_band': pd.Series(df['tgt_band'][0]),\n",
    "                         'intercept': pd.Series(float(LinearRegression().fit(x, y).intercept_)),\n",
    "                         'slope': pd.Series(float(LinearRegression().fit(x, y).coef_))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c10b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makemydir(dir_path):\n",
    "    try:\n",
    "        os.makedirs(dir_path)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8094e177",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "tgt_dir = '/home/hrodenhizer/Documents/permafrost_pathways/rts_mapping/planet_processing_test/data/automated_download/arosics_output/calibrated_files/'\n",
    "tgt_files = []\n",
    "for root, subdirs, files in os.walk(tgt_dir):\n",
    "    for file in files:\n",
    "        if re.match('.*SR.*tif$', file):\n",
    "            tgt_files.append(os.path.join(root, file))\n",
    "            \n",
    "tgt_files = sorted(tgt_files)\n",
    "\n",
    "ref_dir = '/home/hrodenhizer/Documents/permafrost_pathways/rts_mapping/planet_processing_test/data/sentinel_data/yamal_gydan_polygons'\n",
    "ref_files = []\n",
    "for root, subdirs, files in os.walk(ref_dir):\n",
    "    for file in files:\n",
    "        if re.match('.*tif$', file):\n",
    "            ref_files.append(os.path.join(root, file))\n",
    "        \n",
    "mad_out_dir = '/home/hrodenhizer/Documents/permafrost_pathways/rts_mapping/planet_processing_test/data/automated_download/mad_output/mad_files/'\n",
    "makemydir(mad_out_dir)\n",
    "out_dir = '/home/hrodenhizer/Documents/permafrost_pathways/rts_mapping/planet_processing_test/data/automated_download/mad_output/calibrated_files/'\n",
    "makemydir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c5322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run MAD calibration\n",
    "lm_output = pd.DataFrame()\n",
    "for tgt_file in tgt_files:\n",
    "    print(tgt_file)\n",
    "    \n",
    "    # read in target file\n",
    "    bands = [1, 2, 3, 4]\n",
    "    tgt = rxr.open_rasterio(tgt_file).sel(band = bands)\n",
    "    \n",
    "    # find and read in reference file (sentinel-2)\n",
    "    crs = str(tgt.rio.crs).split(':')[1][3:5]\n",
    "    polygon_id = tgt_file.split('/')[-1].split('_')[0]\n",
    "    ref_path = [file for file in ref_files if re.match('.*' + crs + 'N_' + polygon_id + '.tif$', file)][0]\n",
    "    ref = rxr.open_rasterio(ref_path)\n",
    "    \n",
    "    # reproject target file to match Sentinel-2 composite\n",
    "    tgt_reproj = reproj_to_sentinel(tgt, ref)\n",
    "    \n",
    "    # mask target file to ensure nodata is represented by np.nan\n",
    "    tgt_reproj = tgt_reproj.where(tgt_reproj != 0)\n",
    "    \n",
    "    # extract image shape\n",
    "    img_bands, img_height, img_width = tgt_reproj.shape \n",
    "    \n",
    "    # reshape data to be a 1D array for each band\n",
    "    tgt_values = tgt_reproj.values.reshape(img_bands, -1)\n",
    "    ref_values = ref.values.reshape(img_bands, -1)\n",
    "    \n",
    "    # remove missing data for MAD algorithm\n",
    "    non_missing_values = np.where(~np.isnan(tgt_values) & \n",
    "                                  ~np.isnan(ref_values))\n",
    "    tgt_values = tgt_values[non_missing_values].reshape(img_bands, -1)\n",
    "    ref_values = ref_values[non_missing_values].reshape(img_bands, -1)\n",
    "    \n",
    "    # run MAD\n",
    "    mad, can_coo, mad_var, ev_1, ev_2, sigma_11, sigma_22, sigma_12, chi_2, noc_weight = IRMAD(tgt_values, \n",
    "                                                                                               ref_values,\n",
    "                                                                                               max_iter=20,\n",
    "                                                                                               epsilon=1e-3)\n",
    "    k_means_bcm = get_binary_change_map(np.sqrt(chi_2)).reshape(-1)\n",
    "    \n",
    "    # reshape MAD output to reflect shape of input including missing data locations\n",
    "    output = np.empty((img_height*img_width))\n",
    "    output[:] = np.nan\n",
    "    output[non_missing_values[1][np.where(non_missing_values[0] == 0)]] = k_means_bcm\n",
    "    output = np.reshape(output, (img_height, img_width))\n",
    "    \n",
    "    # create a geotiff from MAD results\n",
    "    mad_output = tgt_reproj.sel(band = 1)\n",
    "    mad_output.values = output\n",
    "    mad_output.attrs['long_name'] = 'mad_mask'\n",
    "    \n",
    "    # Save MAD output\n",
    "    mad_output.rio.to_raster(mad_out_dir + tgt_file.split('/')[-1][0:-4] + '_mad.tif')\n",
    "    \n",
    "    # Run linear models on invariant pixels identified with MAD and apply linear correction to each band\n",
    "    tgt_masked = tgt_reproj.where(mad_output == 1)\n",
    "    ref_masked = ref.where(mad_output == 1)\n",
    "    \n",
    "    tgt_cal = tgt.where(tgt != 0)\n",
    "    calibrated_values = list()\n",
    "    for band in bands:\n",
    "        # reshape by band\n",
    "        band_name = tgt_reproj.attrs['long_name'][band-1]\n",
    "        tgt_temp = tgt_masked.sel(band = band).values.reshape(-1)\n",
    "        ref_temp = ref_masked.sel(band = band).values.reshape(-1)\n",
    "        tgt_temp_clean = tgt_temp[~np.isnan(tgt_temp) & ~np.isnan(ref_temp)]\n",
    "        ref_temp_clean = ref_temp[~np.isnan(tgt_temp) & ~np.isnan(ref_temp)]\n",
    "        invariant_pixels = pd.DataFrame({\n",
    "            'tgt_file': tgt_file,\n",
    "            'tgt_band': band_name,\n",
    "            'tgt': tgt_temp_clean,\n",
    "            'ref': ref_temp_clean\n",
    "        })\n",
    "        \n",
    "        # run linear model\n",
    "        lm_current = lm_coefs(invariant_pixels)\n",
    "        print(lm_current)\n",
    "        \n",
    "        # add linear model output to dataframe for export\n",
    "        lm_output = pd.concat([lm_output, lm_current], axis = 0)\n",
    "        \n",
    "        # calculate calibrated raster values\n",
    "        intercept = lm_current['intercept'][0]\n",
    "        slope = lm_current['slope'][0]\n",
    "        calibrated_values.append([\n",
    "            intercept + slope * x \n",
    "            for x in tgt_cal.sel(band = band).values.reshape(-1)\n",
    "        ])\n",
    "    \n",
    "    # reshape calibrated values to reflect output raster shape\n",
    "    calibrated_values = np.array(calibrated_values)\n",
    "    calibrated_values = calibrated_values.reshape(tgt_cal.shape)\n",
    "    \n",
    "    # overwrite raster values with calibrated values\n",
    "    tgt_cal.values = calibrated_values\n",
    "    \n",
    "    # save calibrated file\n",
    "    tgt_cal.rio.to_raster(out_dir + tgt_file.split('/')[-1][0:-4] + '_mad.tif')\n",
    "    print('\\n')\n",
    "\n",
    "lm_output.to_csv('/home/hrodenhizer/Documents/permafrost_pathways/rts_mapping/planet_processing_test/data/calibrated_composite/mad_output/linear_models.csv',\n",
    "                 index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da38b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the MAD processing loop stops running, and needs to be restarted where it left off\n",
    "[x for x in range(len(tgt_files)) if tgt_files[x] == tgt_file][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "298.85px",
    "left": "985px",
    "right": "20px",
    "top": "120px",
    "width": "277px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
