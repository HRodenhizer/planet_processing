{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbddc0dd",
   "metadata": {},
   "source": [
    "# Planet Image Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268a2ad",
   "metadata": {},
   "source": [
    "## API and Package Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ac87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely as shp\n",
    "from pprint import pprint\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import random\n",
    "import urllib.request\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d286b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Planet API Key\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "api_key = os.getenv('PL_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cec214",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de42463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shapefile with AOI (multipolygon)\n",
    "aoi = gpd.read_file(\"/home/hrodenhizer/Documents/permafrost_pathways/rts_mapping/planet_processing_test/data/automated_download/rts_buffer/RTS_buffer.shp\")\n",
    "# convert from multipolygon to multiple polygons\n",
    "aoi = aoi.explode(column = 'geometry', ignore_index = True)\n",
    "# remove inner holes\n",
    "aoi.geometry = aoi.geometry.exterior\n",
    "# convert back to polygon\n",
    "aoi.geometry = [shp.geometry.Polygon([shp.geometry.Point(x, y) for x, y in list(feature.coords)]) for feature in aoi.geometry]\n",
    "# convert to json for planet data search\n",
    "sites = json.loads(aoi.to_json()) # if multiple sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026bc6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import information on images to download\n",
    "images = pd.read_csv('/home/hrodenhizer/Documents/permafrost_pathways/rts_mapping/planet_processing_test/data/automated_download/planet_images_filtered.csv')\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc69b90",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee1d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makemydir(dir_path):\n",
    "    try:\n",
    "        os.makedirs(dir_path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    os.chdir(dir_path) # this changes the working directory - necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b42e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recu_down(url, filename): # recurrent download with ContentTooShortError\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url,filename)\n",
    "    except urllib.error.ContentTooShortError:\n",
    "        print('Download failed. Trying again...')\n",
    "        recu_down(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d919a816",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def download_requested(request_info, dir_path, order_download_path):\n",
    "    order_info = request_info[0]\n",
    "    req = request_info[1]\n",
    "\n",
    "    try:\n",
    "        order_name = order_info['name']\n",
    "        print(order_name)\n",
    "        # Request order_info of scene (This will take some time to complete)\n",
    "\n",
    "        # Poll API to monitor order_info status. Once finished, download and upzip the scene\n",
    "        order_info_succeeded = False\n",
    "        while not order_info_succeeded:\n",
    "            order_info_url = req.json()['_links']['_self']\n",
    "            # Poll API\n",
    "            check_state_request = requests.get(order_info_url, \n",
    "                                               auth=(api_key, ''))\n",
    "            # check_state_request.json()['last_message']\n",
    "            if \"429\" not in str(check_state_request):\n",
    "                # If order process succeeded, we are done\n",
    "                if check_state_request.json()['state'] == 'success':\n",
    "\n",
    "                    download_url0 = check_state_request.json()['_links']['results'][0]  # ['location']\n",
    "                    download_url1 = check_state_request.json()['_links']['results'][1]  # ['location']\n",
    "\n",
    "                    download_urls = [download_url0, download_url1]\n",
    "\n",
    "                    for url in download_urls:\n",
    "                        if url['name'].endswith('.json'):\n",
    "                            manifest_url = url['location']\n",
    "\n",
    "                        if url['name'].endswith('.zip'):\n",
    "                            zip_url = url['location']\n",
    "                    print(\"scene is ready\")\n",
    "                    \n",
    "                    # where to save the zip file\n",
    "                    outfile = os.path.join(dir_path, order_name + \".zip\")\n",
    "                    \n",
    "                    if not os.path.exists(outfile[0:-4]):\n",
    "                        print(\"downloading scene\")\n",
    "                        # download the file\n",
    "                        start_time = time.time()\n",
    "                        recu_down(zip_url, outfile)# the actual download\n",
    "\n",
    "                        elapsed_time = time.time() - start_time\n",
    "                        print(\"downloading time =\", np.round(elapsed_time / 60, 2), \"minutes\")\n",
    "\n",
    "                        # extract the file\n",
    "                        print(\"extracting scene\")\n",
    "                        with zipfile.ZipFile(outfile, 'r') as zip_ref: # unzipping the download\n",
    "                            zip_ref.extractall(outfile[0:-4])\n",
    "\n",
    "                        # remove the downloaded zip file\n",
    "                        os.remove(outfile)\n",
    "                        \n",
    "                    else:\n",
    "                        print('order already downloaded')\n",
    "                    \n",
    "                    # go get the metadata json\n",
    "                    outfile_manifest = os.path.join(dir_path, order_name + \".json\")\n",
    "                    \n",
    "                    if not os.path.exists(outfile_manifest):\n",
    "                        recu_down(manifest_url, outfile_manifest)\n",
    "                        order_info_succeeded = True\n",
    "                        print(\"scene download and extraction complete\")\n",
    "                        download_df = pd.DataFrame({\n",
    "                            'order_info': [order_info],\n",
    "                            'request': [req],\n",
    "                            'downloaded': order_info_succeeded\n",
    "                        })\n",
    "                        download_df.to_csv(order_download_path,\n",
    "                                           index = False,\n",
    "                                           mode = 'a',\n",
    "                                           header = not os.path.exists(order_download_path))\n",
    "\n",
    "                    \n",
    "                else:\n",
    "                    time.sleep(1)\n",
    "            else:\n",
    "                time.sleep(1)\n",
    "\n",
    "        print(\"Images and manifest download completed for {}\".format(order_name))\n",
    "\n",
    "    except:\n",
    "        print(str(order_name) + ' did not download.')\n",
    "        sys.exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39728d01",
   "metadata": {},
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd6da5",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order_info_path = '/home/hrodenhizer/Documents/permafrost_pathways/rts_mapping/planet_processing_test/data/automated_download/planet_images_orders.csv'\n",
    "order_download_path = '/home/hrodenhizer/Documents/permafrost_pathways/rts_mapping/planet_processing_test/data/automated_download/planet_images_downloads.csv'\n",
    "prior_orders = pd.read_csv(order_info_path,\n",
    "                           converters = {'order_info': ast.literal_eval})\n",
    "prior_orders = [row['order_info'] for idx, row in prior_orders.iterrows()]\n",
    "prior_items = [item['products'][0]['item_ids'] for item in prior_orders]\n",
    "\n",
    "for polygon_id, site in enumerate(sites['features']):\n",
    "    \n",
    "    for year in list(np.unique(images.year)[1:5]):\n",
    "\n",
    "        # Make sure there is a directory into which data should be downloaded\n",
    "        dir_path = (\n",
    "            '/home/hrodenhizer/Documents/permafrost_pathways/rts_mapping/planet_processing_test/data/planet_data/yamal_gydan_polygons/polygon_id_'\n",
    "            + str(polygon_id) \n",
    "            + '/' \n",
    "            + str(year)\n",
    "        )\n",
    "        makemydir(dir_path)\n",
    "        \n",
    "        # Get ids for images that we want to request\n",
    "        all_item_ids = list(images[(images.polygon_id == polygon_id) & (images.year == year)]['id'])\n",
    "\n",
    "        # Get image ids for images that have already been downloaded\n",
    "        current_files = glob.glob(os.path.join(dir_path, \"**/*SR_harmonized_clip.tif\"), recursive=True)\n",
    "        current_files = [i.split('/')[-1].split('_3B_Analytic')[0] for i in current_files]\n",
    "\n",
    "        # Filter images to download to avoid repeat downloads\n",
    "        items_to_download = [i for i in all_item_ids if i not in current_files]\n",
    "\n",
    "        print(\"-------------------------------------\")\n",
    "        print(\"\\n\")\n",
    "        print(len(items_to_download), \"items to download for polygon id \" + str(polygon_id) + ', year ' + str(year))\n",
    "        print(\"\\n\")\n",
    "        print(\"-------------------------------------\")\n",
    "\n",
    "        # downloading items in defined chunks -- chunks with fewer images (<10 works better than downloading each chunk with many images\n",
    "\n",
    "        if len(items_to_download) > 0: # if images to download\n",
    "\n",
    "            n_items = 5\n",
    "            n_chunks = int(len(items_to_download) / n_items)\n",
    "            img_chunks = np.array_split(items_to_download, n_chunks)\n",
    "            img_chunks = [list(feature) for feature in img_chunks]\n",
    "            requested_list = []\n",
    "\n",
    "            for chunk_idx, item_ids in enumerate(img_chunks):\n",
    "                print(item_ids)\n",
    "                \n",
    "                if item_ids not in prior_items: # check if an order has already been placed\n",
    "                    now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    chunk_id = now + '_' + str(polygon_id) + '_' + str(year) + '_' + str(chunk_idx)\n",
    "\n",
    "                    # create the order info\n",
    "                    order_info = {\n",
    "                        \"name\": chunk_id,\n",
    "                        \"source_type\": \"scenes\",\n",
    "                        \"products\": [{\n",
    "                            \"item_ids\": item_ids,\n",
    "                            \"item_type\": \"PSScene\",\n",
    "                            \"product_bundle\": \"analytic_sr_udm2,analytic_8b_sr_udm2\"\n",
    "                        }],\n",
    "                        \"tools\": [{\n",
    "                            \"clip\": {\n",
    "                                \"aoi\": {\n",
    "                                        \"type\": \"Polygon\",  # change from Polygon to Multipolygon\n",
    "                                        \"coordinates\": site['geometry']['coordinates']\n",
    "                                }\n",
    "                            }\n",
    "                        }],\n",
    "                        \"delivery\": {\n",
    "                            \"archive_type\": \"zip\",\n",
    "                            \"single_archive\": True,\n",
    "                            \"archive_filename\": \"{{name}}_{{order_id}}.zip\"\n",
    "                        }\n",
    "                    }\n",
    "                \n",
    "                    request_succeeded = False\n",
    "                    print(\"Requesting items...\")\n",
    "                    while not request_succeeded:\n",
    "                        request = requests.post('https://api.planet.com/compute/ops/orders/v2', \n",
    "                                                auth=(api_key, ''),\n",
    "                                                json=order_info)\n",
    "                        print(request)\n",
    "                        print(request.json())\n",
    "\n",
    "                        if \"202\" in str(request):\n",
    "                            requested_list.append([order_info, request])\n",
    "                            request_succeeded = True\n",
    "\n",
    "                            # create and append order info into file\n",
    "                            order_df = pd.DataFrame({\n",
    "                                'polygon_id': polygon_id,\n",
    "                                'year': year,\n",
    "                                'chunk_idx': chunk_idx,\n",
    "                                'order_name': chunk_id,\n",
    "                                'order_info': [request.json()]\n",
    "                            })\n",
    "\n",
    "                            order_df.to_csv(order_info_path,\n",
    "                                            index = False,\n",
    "                                            mode = 'a',\n",
    "                                            header = not os.path.exists(order_info_path)) \n",
    "\n",
    "                        else:\n",
    "                            time.sleep(1) # wait until the request is ready to download\n",
    "                else:\n",
    "                    print('Order already placed.')\n",
    "                    order = prior_orders[[idx for idx, order in enumerate(prior_items) if order == item_ids][0]]\n",
    "                    order_info = {\n",
    "                        \"name\": order['name'],\n",
    "                        \"source_type\": \"scenes\",\n",
    "                        \"products\": [{\n",
    "                            \"item_ids\": item_ids,\n",
    "                            \"item_type\": \"PSScene\",\n",
    "                            \"product_bundle\": \"analytic_sr_udm2,analytic_8b_sr_udm2\"\n",
    "                        }],\n",
    "                        \"tools\": [{\n",
    "                            \"clip\": {\n",
    "                                \"aoi\": {\n",
    "                                        \"type\": \"Polygon\",  # change from Polygon to Multipolygon\n",
    "                                        \"coordinates\": site['geometry']['coordinates']\n",
    "                                }\n",
    "                            }\n",
    "                        }],\n",
    "                        \"delivery\": {\n",
    "                            \"archive_type\": \"zip\",\n",
    "                            \"single_archive\": True,\n",
    "                            \"archive_filename\": \"{{name}}_{{order_id}}.zip\"\n",
    "                        }\n",
    "                    }\n",
    "                    requested_list.append([order_info, \n",
    "                                           requests.get(order['_links']['_self'],\n",
    "                                                        auth=(api_key, ''))])\n",
    "\n",
    "                    order_df = pd.DataFrame({\n",
    "                        'polygon_id': polygon_id,\n",
    "                        'year': year,\n",
    "                        'chunk_idx': chunk_idx,\n",
    "                        'order_name': order['name'],\n",
    "                        'order_info': [order]\n",
    "                    })\n",
    "                    \n",
    "                    if  not os.path.exists(order_info_path):\n",
    "                        print('order info file does not exist')\n",
    "                        order_df.to_csv(order_info_path,\n",
    "                                        index = False,\n",
    "                                        mode = 'a',\n",
    "                                        header = not os.path.exists(order_info_path))\n",
    "                    else:\n",
    "                        print('order info file already exists')\n",
    "                        downloads = pd.read_csv(order_info_path)\n",
    "                        \n",
    "                        if order['name'] not in list(downloads.order_name):\n",
    "                            print('adding order info to order info file')\n",
    "                            order_df.to_csv(order_info_path,\n",
    "                                            index = False,\n",
    "                                            mode = 'a',\n",
    "                                            header = not os.path.exists(order_info_path))\n",
    "\n",
    "            if len(requested_list) > 0:\n",
    "                print('items to download')\n",
    "\n",
    "                for request_info in requested_list:\n",
    "                    download_requested(request_info, dir_path, order_download_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d91f7af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
