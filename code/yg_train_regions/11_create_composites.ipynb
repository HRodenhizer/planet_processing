{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79239afb",
   "metadata": {},
   "source": [
    "# Create Annual Calibrated Composite Images for Each RTS Polygon\n",
    "## TODO:\n",
    "- use `ee.data.listOperations()` to monitor and retry failed exports?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc4c23e",
   "metadata": {},
   "source": [
    "## Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f44ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import geemap\n",
    "import os\n",
    "from pprint import pprint\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely as shp\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import time\n",
    "from collections import Counter\n",
    "import re\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up access to abrupt_thaw\n",
    "storage_client = storage.Client(project=\"AbruptThawMapping\")\n",
    "abrupt_thaw = storage_client.get_bucket('abrupt_thaw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae7040e",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae54d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Properties to allow filtering\n",
    "def setID(image):\n",
    "    img_id = image.id();\n",
    "    img_prop = image.setMulti({'ID': img_id});\n",
    "    img_prop = ee.Image(img_prop);\n",
    "    return img_prop;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823101ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get UTM zone from WGS84 lat and lon\n",
    "def utm_from_wgs84(lon, lat):\n",
    "    #Special Cases for Norway and Svalbard\n",
    "    if (lat > 55 and lat < 64 and lon > 2 and lon < 6):\n",
    "        return 32\n",
    "    elif (lat > 71 and lon >= 6 and lon < 9):\n",
    "        return 31\n",
    "    elif (lat > 71 and ((lon >= 9 and lon < 12) or (lon >= 18 and lon < 21))):\n",
    "        return 33\n",
    "    elif (lat > 71 and ((lon >= 21 and lon < 24) or (lon >= 30 and lon < 33))):\n",
    "        return 35\n",
    "    # Rest of the world\n",
    "    elif (lon >= -180 and lon <= 180):\n",
    "        return 32600 + (math.floor((lon + 180) / 6) % 60) + 1 # 32600 for northern hemisphere\n",
    "    else:\n",
    "        raise ValueError('Cannot figure out UTM zone from given Lat: {0}, Lon: {1}.'.format(lat, lon))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa75a44b",
   "metadata": {},
   "source": [
    "## Import Data and Prepare Visualization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ae341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Planet Data GCS\n",
    "planet = ee.ImageCollection('projects/abruptthawmapping/assets/yg_train_regions_imagery_calibrated')\n",
    "planet = planet.map(setID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72839ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "planet.first().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep Map\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(planet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b542ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the imagery\n",
    "vis_params_imagery = {\n",
    "    'min': [470, 415, 280],'max': [1180, 930, 750],\n",
    "    'bands': ['red', 'green', 'blue'],\n",
    "    'gamma': 0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486cbb80",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ba62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask the data to values greater than 0 (which is how nodata gets imported into GEE by default)\n",
    "def mask_0(image):\n",
    "    mask = image.gt(0)\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "planet = planet.map(mask_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0f520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2017, 2018, 2019, 2020, 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0584fd30",
   "metadata": {},
   "source": [
    "## Create Annual Composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa827c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a composite image across all regions for each year individually and all years combined\n",
    "planet_composite_2017 = planet.filter(ee.Filter.stringContains('ID', '2017')).median()\n",
    "planet_composite_2018 = planet.filter(ee.Filter.stringContains('ID', '2018')).median()\n",
    "planet_composite_2019 = planet.filter(ee.Filter.stringContains('ID', '2019')).median()\n",
    "planet_composite_2020 = planet.filter(ee.Filter.stringContains('ID', '2020')).median()\n",
    "planet_composite_2021 = planet.filter(ee.Filter.stringContains('ID', '2021')).median()\n",
    "\n",
    "planet_composite_all = planet.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5891a1e",
   "metadata": {},
   "source": [
    "## Map Composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35509278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add composites to the map as one layer\n",
    "Map.addLayer(planet_composite_2017,\n",
    "             vis_params_imagery,\n",
    "             '2017 Composites')\n",
    "Map.addLayer(planet_composite_2018,\n",
    "             vis_params_imagery,\n",
    "             '2018 Composites')\n",
    "Map.addLayer(planet_composite_2019,\n",
    "             vis_params_imagery,\n",
    "             '2019 Composites')\n",
    "Map.addLayer(planet_composite_2020,\n",
    "             vis_params_imagery,\n",
    "             '2020 Composites')\n",
    "Map.addLayer(planet_composite_2021,\n",
    "             vis_params_imagery,\n",
    "             '2021 Composites')\n",
    "Map.addLayer(planet_composite_all,\n",
    "             vis_params_imagery,\n",
    "             'All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e505ab32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189242e4",
   "metadata": {},
   "source": [
    "## Export Annual Composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shapefile with AOI (multipolygon)\n",
    "aoi = gpd.read_file(\"/home/hrodenhizer/Documents/permafrost_pathways/rts_mapping/planet_processing_test/data/yg_train_regions/bboxes/RTS_buffer_separate.shp\")\n",
    "aoi['pid'] = aoi.index\n",
    "# convert to json\n",
    "sites = json.loads(aoi.to_json()) # if multiple sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62374012",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = pd.DataFrame(columns = ['pid', 'utm_zone'])\n",
    "for idx, pid in enumerate(aoi.geometry):\n",
    "    pid_zones = []\n",
    "    for x, y in zip(pid.exterior.coords.xy[0], pid.exterior.coords.xy[1]):\n",
    "        pid_zones.append(utm_from_wgs84(x, y))\n",
    "        \n",
    "    pid_zones = round(statistics.median(pid_zones))\n",
    "    temp_df = pd.DataFrame({'pid': [idx],\n",
    "                            'utm_zone': [pid_zones]})\n",
    "    zones = pd.concat([zones, temp_df])\n",
    "zones = zones.set_index('pid')  \n",
    "zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d74c9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Export Composites to GCS (2017)\n",
    "# for pid in aoi.pid:\n",
    "#     name = 'yg_train_regions_' + str(pid) + '_2017_composite'\n",
    "#     geometry = sites['features'][pid]['geometry']['coordinates']\n",
    "#     scale = 3\n",
    "#     crs = 'EPSG:' + str(zones.iloc[pid].utm_zone)\n",
    "#     task = ee.batch.Export.image.toCloudStorage(\n",
    "#         image = planet_composite_2017,\n",
    "#         description = name,\n",
    "#         bucket = 'abrupt_thaw',\n",
    "#         fileNamePrefix = 'planet_processing/data/yg_train_regions/calibrated_composites/' + name,\n",
    "#         crs = crs,\n",
    "#         region = geometry,\n",
    "#         scale = scale,\n",
    "#         maxPixels = 1e13,\n",
    "#         fileFormat = 'GeoTIFF',\n",
    "#         formatOptions = {'cloudOptimized': True}\n",
    "#     )\n",
    "#     task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c6833f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Export Composites to Drive (2018)\n",
    "# for pid in aoi.pid:\n",
    "#     name = 'yg_train_regions_' + str(pid) + '_2018_composite'\n",
    "#     geometry = sites['features'][pid]['geometry']['coordinates']\n",
    "#     scale = 3\n",
    "#     crs = 'EPSG:' + str(zones.iloc[pid].utm_zone)\n",
    "#     task = ee.batch.Export.image.toCloudStorage(\n",
    "#         image = planet_composite_2018,\n",
    "#         description = name,\n",
    "#         bucket = 'abrupt_thaw',\n",
    "#         fileNamePrefix = 'planet_processing/data/yg_train_regions/calibrated_composites/' + name,\n",
    "#         crs = crs,\n",
    "#         region = geometry,\n",
    "#         scale = scale,\n",
    "#         maxPixels = 1e13,\n",
    "#         fileFormat = 'GeoTIFF',\n",
    "#         formatOptions = {'cloudOptimized': True}\n",
    "#     )\n",
    "#     task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c0fec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Export Composites to Drive (2019)\n",
    "# for pid in aoi.pid:\n",
    "#     name = 'yg_train_regions_' + str(pid) + '_2019_composite'\n",
    "#     geometry = sites['features'][pid]['geometry']['coordinates']\n",
    "#     scale = 3\n",
    "#     crs = 'EPSG:' + str(zones.iloc[pid].utm_zone)\n",
    "#     task = ee.batch.Export.image.toCloudStorage(\n",
    "#         image = planet_composite_2019,\n",
    "#         description = name,\n",
    "#         bucket = 'abrupt_thaw',\n",
    "#         fileNamePrefix = 'planet_processing/data/yg_train_regions/calibrated_composites/' + name,\n",
    "#         crs = crs,\n",
    "#         region = geometry,\n",
    "#         scale = scale,\n",
    "#         maxPixels = 1e13,\n",
    "#         fileFormat = 'GeoTIFF',\n",
    "#         formatOptions = {'cloudOptimized': True}\n",
    "#     )\n",
    "#     task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c0225",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Export Composites to Drive (2020)\n",
    "# for pid in aoi.pid:\n",
    "#     name = 'yg_train_regions_' + str(pid) + '_2020_composite'\n",
    "#     geometry = sites['features'][pid]['geometry']['coordinates']\n",
    "#     scale = 3\n",
    "#     crs = 'EPSG:' + str(zones.iloc[pid].utm_zone)\n",
    "#     task = ee.batch.Export.image.toCloudStorage(\n",
    "#         image = planet_composite_2020,\n",
    "#         description = name,\n",
    "#         bucket = 'abrupt_thaw',\n",
    "#         fileNamePrefix = 'planet_processing/data/yg_train_regions/calibrated_composites/' + name,\n",
    "#         crs = crs,\n",
    "#         region = geometry,\n",
    "#         scale = scale,\n",
    "#         maxPixels = 1e13,\n",
    "#         fileFormat = 'GeoTIFF',\n",
    "#         formatOptions = {'cloudOptimized': True}\n",
    "#     )\n",
    "#     task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f351a8df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Export Composites to Drive (2021)\n",
    "# for pid in aoi.pid:\n",
    "#     name = 'yg_train_regions_' + str(pid) + '_2021_composite'\n",
    "#     geometry = sites['features'][pid]['geometry']['coordinates']\n",
    "#     scale = 3\n",
    "#     crs = 'EPSG:' + str(zones.iloc[pid].utm_zone)\n",
    "#     task = ee.batch.Export.image.toCloudStorage(\n",
    "#         image = planet_composite_2021,\n",
    "#         description = name,\n",
    "#         bucket = 'abrupt_thaw',\n",
    "#         fileNamePrefix = 'planet_processing/data/yg_train_regions/calibrated_composites/' + name,\n",
    "#         crs = crs,\n",
    "#         region = geometry,\n",
    "#         scale = scale,\n",
    "#         maxPixels = 1e13,\n",
    "#         fileFormat = 'GeoTIFF',\n",
    "#         formatOptions = {'cloudOptimized': True}\n",
    "#     )\n",
    "#     task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d269a565",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Export Composites to Drive (all)\n",
    "# for pid in aoi.pid:\n",
    "#     name = 'yg_train_regions_' + str(pid) + '_all_composite'\n",
    "#     geometry = sites['features'][pid]['geometry']['coordinates']\n",
    "#     scale = 3\n",
    "#     crs = 'EPSG:' + str(zones.iloc[pid].utm_zone)\n",
    "#     task = ee.batch.Export.image.toCloudStorage(\n",
    "#         image = planet_composite_all,\n",
    "#         description = name,\n",
    "#         bucket = 'abrupt_thaw',\n",
    "#         fileNamePrefix = 'planet_processing/data/yg_train_regions/calibrated_composites/' + name,\n",
    "#         crs = crs,\n",
    "#         region = geometry,\n",
    "#         scale = scale,\n",
    "#         maxPixels = 1e13,\n",
    "#         fileFormat = 'GeoTIFF',\n",
    "#         formatOptions = {'cloudOptimized': True}\n",
    "#     )\n",
    "#     task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b431d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Monitor tasks and restart as needed\n",
    "# # currently, this keeps failed tasks in current_info and then \n",
    "# # continues to restart that task indefinitely...\n",
    "# # need to figure out how to remove failed tasks from current_info\n",
    "# # after restarting\n",
    "# start_time_all = datetime.now(tz = timezone(timedelta(hours = 0))).isoformat()\n",
    "# for pid in [47]:\n",
    "#     name = 'yg_train_regions_' + str(pid) + '_all_composite'\n",
    "#     geometry = sites['features'][pid]['geometry']['coordinates']\n",
    "#     scale = 3\n",
    "#     crs = 'EPSG:' + str(zones.iloc[pid].utm_zone)\n",
    "#     task = ee.batch.Export.image.toCloudStorage(\n",
    "#         image = planet_composite_all,\n",
    "#         description = name,\n",
    "#         bucket = 'abrupt_thaw',\n",
    "#         fileNamePrefix = 'planet_processing/data/yg_train_regions/calibrated_composites/' + name,\n",
    "#         crs = crs,\n",
    "#         region = geometry,\n",
    "#         scale = scale,\n",
    "#         maxPixels = 1e13,\n",
    "#         fileFormat = 'GeoTIFF',\n",
    "#         formatOptions = {'cloudOptimized': True}\n",
    "#     )\n",
    "#     task.start()\n",
    "# tasks = ee.data.listOperations()\n",
    "# current_tasks = [task['metadata']['description'] for task in tasks \n",
    "#           if task['metadata']['createTime'] >= start_time_all]\n",
    "# current_info = [{'name': task['metadata']['description'], \n",
    "#                  'state': task['metadata']['state']}\n",
    "#                 for task in tasks \n",
    "#                 if task['metadata']['description'] in current_tasks\n",
    "#                 and task['metadata']['createTime'] >= start_time_all]\n",
    "    \n",
    "# repeated_tasks = []\n",
    "# while np.any([task['state'] in ['PENDING', 'RUNNING']\n",
    "#               for task in current_info]):\n",
    "#     # Check if any tasks have failed\n",
    "#     any_failed = np.any([task['state'] == 'FAILED' for task in current_info])\n",
    "#     if any_failed:\n",
    "#         # Restart tasks that failed\n",
    "#         names = [task['name'] for task in current_info \n",
    "#                   if task['state'] == 'FAILED']\n",
    "#         pids = [int(name.split('_')[3]) for name in names]\n",
    "#         print('That sucks,', names, 'failed. Restarting this(these) task(s).')\n",
    "#         repeated_tasks = [repeated_tasks.append(name) for name in names]\n",
    "        \n",
    "#         for pid, name in zip(pids, names):\n",
    "#             geometry = sites['features'][pid]['geometry']['coordinates']\n",
    "#             scale = 3\n",
    "#             crs = 'EPSG:' + str(zones.iloc[pid].utm_zone)\n",
    "#             task = ee.batch.Export.image.toCloudStorage(\n",
    "#                 image = planet_composite_all,\n",
    "#                 description = name,\n",
    "#                 bucket = 'abrupt_thaw',\n",
    "#                 fileNamePrefix = 'planet_processing/data/yg_train_regions/calibrated_composites/' + name,\n",
    "#                 crs = crs,\n",
    "#                 region = geometry,\n",
    "#                 scale = scale,\n",
    "#                 maxPixels = 1e13,\n",
    "#                 fileFormat = 'GeoTIFF',\n",
    "#                 formatOptions = {'cloudOptimized': True}\n",
    "#             )\n",
    "#             task.start()\n",
    "    \n",
    "#     # Check if any tasks have succeeded\n",
    "#     any_succeeded = np.any([task['state'] == 'SUCCESS' for task in current_info])\n",
    "#     if any_succeeded:\n",
    "#         # Remove finished tasks from list of tasks\n",
    "#         succeeded = [task['name'] for task in current_info if task['state'] == 'SUCCESS']\n",
    "#         print(succeeded, 'succeeded.')\n",
    "#         current_tasks = [task for task in current_tasks if task not in succeeded]\n",
    "#         print('Still need to export', current_tasks)\n",
    "    \n",
    "#     # Wait ten seconds, then check task status again\n",
    "#     time.sleep(10)\n",
    "#     tasks = ee.data.listOperations()\n",
    "#     # Make sure old failed tasks are not included\n",
    "#     current_info = [{'name': task['metadata']['description'], \n",
    "#                      'state': task['metadata']['state']}\n",
    "#                     for task in tasks\n",
    "#                     if task['metadata']['description'] in current_tasks\n",
    "#                     and task['metadata']['createTime'] >= start_time_all\n",
    "#                     and (\n",
    "#                         task['metadata']['description'] not in repeated_tasks \n",
    "#                         or (task['metadata']['description'] in repeated_tasks \n",
    "#                             and task['metadata']['state'] != 'FAILED')\n",
    "#                     )]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf07946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
