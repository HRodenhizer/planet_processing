{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a3b02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e0f663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import geemap\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import shapely as shp\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca41f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometryToEE(img_geometry):\n",
    "    \n",
    "    # format geometry\n",
    "#     img_geometry = gpd.GeoDataFrame(geometry = img_geometry)\n",
    "    print(img_geometry)\n",
    "    img_geometry = img_geometry.reset_index(drop = True)\n",
    "    img_geometry = [[[x, y] for x, y in list(img_geometry.geometry.exterior[0].coords)]]\n",
    "    \n",
    "    # convert geometry to ee.Geometry\n",
    "    img_geometry_ee = ee.Geometry({\n",
    "        'type': 'Polygon',\n",
    "        'coordinates': img_geometry\n",
    "    })\n",
    "    \n",
    "    return img_geometry_ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e624248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in RTS polygons\n",
    "polys = (ee.FeatureCollection('users/gfiske/FrostCraters/rts_polygons_for_Yili_May_2022')\n",
    "         .filter(ee.Filter.bounds(ee.Geometry.BBox(65, 68, 81, 73))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep Map\n",
    "Map = geemap.Map()\n",
    "Map.setCenter(73, 70.5, 7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d7a8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get Sentinel-2 Mosaic to Align Planet Data\n",
    "MAX_CLOUD_PROBABILITY = 50\n",
    "# geometry = ee.Geometry({\n",
    "#     'type': 'Polygon',\n",
    "#     'coordinates': [[\n",
    "#         [66, 66],\n",
    "#         [66, 73.5],\n",
    "#         [85, 73.5],\n",
    "#         [85, 66],\n",
    "#         [66, 66]\n",
    "#         ]]\n",
    "# })\n",
    "\n",
    "s2 = (\n",
    "    ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "#     .filterBounds(geometry)\n",
    "    .filterDate('2018-06-15', '2019-08-31')\n",
    "    .filter(ee.Filter.dayOfYear(182, 243))\n",
    ");\n",
    "\n",
    "s2_clouds = (\n",
    "    ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "#     .filterBounds(geometry)\n",
    "    .filterDate('2018-06-15', '2019-08-31')\n",
    "    .filter(ee.Filter.dayOfYear(182, 243))\n",
    ");\n",
    "\n",
    "def s2_maskcloud(image):\n",
    "    \n",
    "    clouds = ee.Image(image.get('cloud_mask')).select('probability')\n",
    "    \n",
    "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
    "    \n",
    "    return image.updateMask(isNotCloud)\n",
    "\n",
    "# Join S2 SR with cloud probability dataset to add cloud mask.\n",
    "s2_with_clouds = ee.Join.saveFirst('cloud_mask').apply(    \n",
    "  primary=s2,\n",
    "  secondary=s2_clouds,\n",
    "  condition=ee.Filter.equals(leftField='system:index', rightField='system:index'))\n",
    "\n",
    "s2_masked = ee.ImageCollection(s2_with_clouds).map(s2_maskcloud)\n",
    "\n",
    "# s2_masked_north = s2_masked.filter(ee.Filter.dayOfYear(196, 243))\n",
    "\n",
    "s2_mosaic = (\n",
    "    s2_masked\n",
    "    .select(['B2', 'B3', 'B4', 'B8'])\n",
    "    .median());\n",
    "\n",
    "# s2_mosaic_north = (\n",
    "#     s2_masked_north\n",
    "#     .select(['B2', 'B3', 'B4', 'B8'])\n",
    "#     .median());\n",
    "\n",
    "pprint(s2_mosaic.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f359edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export only in the polygons we need\n",
    "# Import shapefile with AOI (multipolygon)\n",
    "aoi = gpd.read_file(\"/home/hrodenhizer/Documents/permafrost_pathways/rts_mapping/planet_processing_test/data/yg_val_regions/bboxes/yg_validation_bboxes.shp\")\n",
    "# convert from multipolygon to multiple polygons\n",
    "aoi = aoi.explode(column = 'geometry', ignore_index = True)\n",
    "# remove inner holes\n",
    "aoi.geometry = aoi.geometry.exterior\n",
    "# convert back to polygon\n",
    "aoi.geometry = [shp.geometry.Polygon([shp.geometry.Point(x, y) for x, y in list(feature.coords)]) for feature in aoi.geometry]\n",
    "aoi.geometry = aoi.geometry.to_crs(crs = 32642).buffer(1000, join_style = 2).to_crs(crs = 4326)\n",
    "pprint(aoi)\n",
    "\n",
    "# convert to ee.Geometry objects\n",
    "aoi_ee_0 = geometryToEE(aoi[0:1])\n",
    "aoi_ee_1 = geometryToEE(aoi[1:2])\n",
    "aoi_ee_2 = geometryToEE(aoi[2:3])\n",
    "aoi_ee_3 = geometryToEE(aoi[3:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7a1665",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(s2_mosaic.clip(aoi_ee_0), \n",
    "             {'bands':['B4', 'B3', 'B2'], 'min':0, 'max':1000}, \n",
    "             'S2 All Years, Region 1')\n",
    "Map.addLayer(s2_mosaic.clip(aoi_ee_1), \n",
    "             {'bands':['B4', 'B3', 'B2'], 'min':0, 'max':1200}, \n",
    "             'S2 All Years, Region 2')\n",
    "Map.addLayer(s2_mosaic.clip(aoi_ee_2), \n",
    "             {'bands':['B4', 'B3', 'B2'], 'min':0, 'max':1200}, \n",
    "             'S2 All Years, Region 3')\n",
    "Map.addLayer(s2_mosaic.clip(aoi_ee_3), \n",
    "             {'bands':['B4', 'B3', 'B2'], 'min':0, 'max':1200}, \n",
    "             'S2 All Years, Region 4')\n",
    "Map.addLayer(polys,\n",
    "             {'color': 'red'},\n",
    "             'RTS Polygons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b3c54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbfd055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def utm_from_wgs84(lon, lat):\n",
    "    #Special Cases for Norway and Svalbard\n",
    "    if (lat > 55 and lat < 64 and lon > 2 and lon < 6):\n",
    "        return 32\n",
    "    elif (lat > 71 and lon >= 6 and lon < 9):\n",
    "        return 31\n",
    "    elif (lat > 71 and ((lon >= 9 and lon < 12) or (lon >= 18 and lon < 21))):\n",
    "        return 33\n",
    "    elif (lat > 71 and ((lon >= 21 and lon < 24) or (lon >= 30 and lon < 33))):\n",
    "        return 35\n",
    "    # Rest of the world\n",
    "    elif (lon >= -180 and lon <= 180):\n",
    "        return 32600 + (math.floor((lon + 180) / 6) % 60) + 1 # 32600 for northern hemisphere\n",
    "    else:\n",
    "        raise ValueError('Cannot figure out UTM zone from given Lat: {0}, Lon: {1}.'.format(lat, lon))\n",
    "\n",
    "zones = pd.DataFrame(columns = ['region', 'utm_zone'])\n",
    "for idx, region in enumerate(aoi.geometry):\n",
    "    region_zones = []\n",
    "    for x, y in zip(region.exterior.coords.xy[0], region.exterior.coords.xy[1]):\n",
    "        region_zones.append(utm_from_wgs84(x, y))\n",
    "        \n",
    "    region_zones = set(region_zones)\n",
    "    temp_df = pd.DataFrame({'region': [idx]*len(region_zones),\n",
    "                            'utm_zone': list(region_zones)})\n",
    "    zones = pd.concat([zones, temp_df])\n",
    "zones = zones.set_index('region')  \n",
    "zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4217057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = pd.merge(aoi, zones, left_index = True, right_index = True)\n",
    "aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03fa1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in aoi.iterrows():\n",
    "    polygon_id = row[0]\n",
    "    description = 'Sentinel-2_YG_Validation_mosaic_bgrnir_Region_' + str(row[0]) + '_UTM' + str(row[1]['utm_zone']-32600) + 'N'\n",
    "    name = 'planet_processing/data/yg_val_regions/sentinel_data/Sentinel-2_YG_Validation_mosaic_bgrnir_Region_' + str(row[0]) + '_UTM' + str(row[1]['utm_zone']-32600) + 'N'\n",
    "    img_geometry = [[[x, y] for x, y in list(row[1]['geometry'].exterior.coords)]]\n",
    "    \n",
    "    crs = 'EPSG:' + str(row[1]['utm_zone'])\n",
    "   \n",
    "    # Export 2018-2019 growing season Sentinel-2 Mosaic to Drive\n",
    "    task = ee.batch.Export.image.toCloudStorage(\n",
    "        image = s2_mosaic,\n",
    "        description = description,\n",
    "        bucket = 'abrupt_thaw',\n",
    "        fileNamePrefix = name,\n",
    "        crs = crs,\n",
    "        scale = 10,\n",
    "        maxPixels = 1e13,\n",
    "        region = img_geometry,\n",
    "        fileFormat = 'GeoTIFF',\n",
    "        formatOptions = {\n",
    "            'cloudOptimized': True\n",
    "        }\n",
    "    )\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed61f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
